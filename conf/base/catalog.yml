# Here you can define all your data sets by using simple YAML syntax.
#
# Documentation for this file format can be found in "The Data Catalog"
# Link: https://kedro.readthedocs.io/en/stable/data/data_catalog.html

random_data:
  type: pandas.GBQTableDataSet
  dataset: kedro_sample
  table_name: random_data
  project: dcc-manufacturing-dev-ejp
random_big_data@pandas:
  type: pandas.GBQTableDataSet
  dataset: kedro_sample
  table_name: random_big_data
  project: dcc-manufacturing-dev-ejp
random_big_data@spark:
  type: spark.SparkDataSet
  filepath: ""
  file_format: "bigquery"
  load_args:
    table: kedro_sample:random_big_data

# see docs https://cloud.google.com/dataproc/docs/tutorials/bigquery-connector-spark-example
summed_data:
  type: spark.SparkDataSet
  file_format: "bigquery"
  filepath: ""
  load_args:
    table: kedro_sample:summed_data
  save_args:
    table: kedro_sample:summed_data