spark.kubernetes.container.image: europe-west4-docker.pkg.dev/dcc-manufacturing-dev-ejp/spark-k8s/kedro-vertex-spark
spark.master: k8s://https://34.91.90.197:443
# spark.kubernetes.namespace: "default"
spark.executor.instances: "3"
spark.executor.cores: "1"
spark.driver.memory: "512m"
spark.executor.memory: "512m"
spark.kubernetes.pyspark.pythonVersion: "3"
# spark.kubernetes.authenticate.driver.serviceAccountName: "spark"
# spark.kubernetes.authenticate.serviceAccountName: "spark"
spark.driver.bindAddress: "0.0.0.0"
spark.driver.port: "29413"
spark.driver.host: "10.132.0.43" # should be dynamically based on the workbench IP
spark.jars: jars/spark-3.1-bigquery-0.27.0-preview.jar
spark.temporaryGcsBucket: tmp-pascalwhoop